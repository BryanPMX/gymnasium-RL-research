experiment_name: "dqn_part3_demo"
env_id: "LunarLander-v2"

seeds: [42]

training:
  episodes: 30
  max_steps_per_episode: 1000
  gamma: 0.99
  
  # epsilon-greedy exploration
  epsilon_start: 1.0
  epsilon_end: 0.05
  epsilon_decay: 0.995
  
  # replay buffer
  replay_capacity: 50000
  batch_size: 128
  min_buffer_size: 200
  
  # target network + optimization
  target_update_freq: 1000
  learning_rate: 0.0003
  gradient_clip_norm: 5.0
  
  # logging & eval
  log_interval: 5
  eval_interval: 15
  eval_episodes: 5
  moving_avg_window: 10
  checkpoint_interval: 30
  
  use_per: false  # Use regular replay for demo
  use_reward_shaping: true
  use_curriculum: false
