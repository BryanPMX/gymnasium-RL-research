experiment_name: "ppo_part3_demo"
env_id: "LunarLander-v2"

seeds: [42]

training:
  episodes: 30
  max_steps_per_episode: 1000

  # PPO hyperparams
  learning_rate: 0.0003
  gamma: 0.99
  clip_epsilon: 0.2
  value_coef: 0.5
  entropy_coef: 0.01
  update_epochs: 10
  batch_size: 64

  # Wrappers / curriculum
  use_reward_shaping: true
  use_curriculum: true

  # Logging / eval
  log_interval: 5
  eval_interval: 15
  eval_episodes: 5
  moving_avg_window: 10
